import os
import json
import time
import pandas as pd
import openai
from dotenv import load_dotenv
from tqdm import tqdm

# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(".env")

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
INPUT_FILE = r'E:\projects\risk-pipeline\data\output\climaterisk_final_sample.csv'
# æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
OUTPUT_FILE = r'E:\projects\risk-pipeline\data\output\climaterisk_LLM_Full_Labeled.csv'
# ä¸­æ–­å¤‡ä»½æ–‡ä»¶ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
CHECKPOINT_FILE = r'E:\projects\risk-pipeline\data\output\label_checkpoint.tmp'

def setup_client():
    api_key = os.getenv("DEEP_API_KEY")
    base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
    if not api_key:
        raise ValueError("âŒ é”™è¯¯: æœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ° DEEP_API_KEY")
    return openai.OpenAI(api_key=api_key, base_url=base_url)

# ================= Prompt è®¾è®¡ =================
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ°”å€™é‡‘èä¸“å®¶ã€‚åˆ†ææ–‡æœ¬è¯­ä¹‰å¹¶è¾“å‡º JSONï¼š
1. ã€æš´éœ²ã€‘ (-1)ï¼šå…·ä½“æè¿°äº†æ°”å€™ç¾å®³æŸå¤±ã€èµ„äº§å‡å€¼æˆ–åˆè§„æˆæœ¬ä¸Šå‡ã€‚
2. ã€é˜²èŒƒã€‘ (1)ï¼šå…·ä½“æè¿°äº†å‡æ’æŠ•å…¥ã€è½¬å‹æŠ€æœ¯ã€ç®¡ç†æ¶æ„æˆ–æ˜ç¡®ç›®æ ‡ã€‚
3. ã€ä¸ç›¸å…³ã€‘ (0)ï¼šç©ºæ´å£å·ã€æ´—ç»¿è¯æœ¯æˆ–å•çº¯æ”¿ç­–å¤è¿°ã€‚

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
{
  "label": -1,
  "prob_exposed": 0.8,
  "prob_prevent": 0.1,
  "prob_neutral": 0.1,
  "reason": "å†…å®¹æè¿°äº†æç«¯å¤©æ°”å¯¼è‡´çš„ä¾›åº”é“¾ä¸­æ–­"
}"""

def main():
    client = setup_client()
    
    # 1. åŠ è½½å…¨é‡æ•°æ®
    df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig')
    total_count = len(df)
    
    # 2. æ£€æŸ¥æ˜¯å¦æœ‰æ–­ç‚¹ï¼ˆç»­ä¼ é€»è¾‘ï¼‰
    if os.path.exists(CHECKPOINT_FILE):
        processed_df = pd.read_csv(CHECKPOINT_FILE, encoding='utf-8-sig')
        start_idx = len(processed_df)
        print(f"ğŸ”„ æ£€æµ‹åˆ°æ–­ç‚¹ï¼Œä»ç¬¬ {start_idx} æ¡å¼€å§‹ç»­ä¼ ...")
    else:
        processed_df = pd.DataFrame()
        start_idx = 0
        print(f"ğŸš€ å…¨é‡æ¨¡å¼å¯åŠ¨ï¼Œå…±è®¡ {total_count} æ¡å¾…æ ‡æ³¨...")

    # 3. æ ¸å¿ƒæ¨ç†å¾ªç¯
    # ä»…å¤„ç†å°šæœªæ ‡æ³¨çš„éƒ¨åˆ†
    target_sentences = df['å¥å­'].iloc[start_idx:].tolist()
    
    for i, text in enumerate(tqdm(target_sentences, desc="DeepSeek æ ‡æ³¨ä¸­", initial=start_idx, total=total_count)):
        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": f"æ–‡æœ¬ï¼š{text}"}
                ],
                response_format={'type': 'json_object'},
                temperature=0.1
            )
            
            # è§£æå†…å®¹
            data = json.loads(response.choices[0].message.content)
            
            # æ•´ç†å½“å‰è¡Œæ•°æ®
            current_row = df.iloc[[start_idx + i]].copy()
            current_row['LLM_Label'] = data.get('label')
            current_row['LLM_Prob_Exposed'] = data.get('prob_exposed')
            current_row['LLM_Prob_Prevent'] = data.get('prob_prevent')
            current_row['LLM_Prob_Neutral'] = data.get('prob_neutral')
            current_row['LLM_Reason'] = data.get('reason')
            
            # å®æ—¶è¿½åŠ åˆ°å·²å¤„ç† DataFrame
            processed_df = pd.concat([processed_df, current_row], ignore_index=True)
            
            # æ¯ 10 æ¡ä¿å­˜ä¸€æ¬¡ä¸´æ—¶æ–‡ä»¶ï¼Œé˜²æ­¢æ–­ç”µ
            if (i + 1) % 10 == 0:
                processed_df.to_csv(CHECKPOINT_FILE, index=False, encoding='utf-8-sig')
                
        except Exception as e:
            print(f"\nâš ï¸ å¤„ç†ç¬¬ {start_idx + i} æ¡æ—¶å‡ºé”™: {e}")
            # ä¿å­˜å½“å‰è¿›åº¦å¹¶é€€å‡ºï¼Œæ–¹ä¾¿ç¨åé‡å¯
            processed_df.to_csv(CHECKPOINT_FILE, index=False, encoding='utf-8-sig')
            print("ğŸ’¾ è¿›åº¦å·²å®‰å…¨ä¿å­˜è‡³ä¸´æ—¶æ–‡ä»¶ã€‚")
            break
        
        # é’ˆå¯¹å…¨é‡æ ‡æ³¨å¾®è°ƒå»¶è¿Ÿ
        time.sleep(0.05)

    # 4. å®Œæˆåä¿å­˜æœ€ç»ˆæ–‡ä»¶å¹¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if len(processed_df) >= total_count:
        processed_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
        if os.path.exists(CHECKPOINT_FILE):
            os.remove(CHECKPOINT_FILE)
        print(f"\nâœ… å…¨é‡æ ‡æ³¨ä»»åŠ¡å·²åœ†æ»¡å®Œæˆï¼ç»“æœä¿å­˜è‡³: {OUTPUT_FILE}")
    else:
        print(f"\nâ¸ï¸ ä»»åŠ¡æš‚åœï¼Œå·²å®Œæˆ {len(processed_df)} / {total_count}ã€‚è¯·æ£€æŸ¥ç½‘ç»œåé‡å¯ã€‚")

if __name__ == "__main__":
    main()